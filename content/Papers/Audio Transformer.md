---
paper: https://arxiv.org/pdf/2105.00335
date: 05-01-2021
---
## Notable References

- [A framework for contrastive and generative learning of audio representations](https://arxiv.org/abs/2010.11459)
- [Deep residual learning for image recognition](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)
- [Audio set: An ontology and human-labeled dataset for audio events](https://ieeexplore.ieee.org/document/7952965)
- [Progen: Language modeling for protein generation](https://arxiv.org/abs/2004.03497)
- [Language models are few-shot learners](https://arxiv.org/abs/2005.14165)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
- [Music Transformer](https://arxiv.org/abs/1809.04281)
- [VideoBERT: A joint model for video and language representation learning](https://openaccess.thecvf.com/content_ICCV_2019/papers/Sun_VideoBERT_A_Joint_Model_for_Video_and_Language_Representation_Learning_ICCV_2019_paper.html)
- [Video action transformer network](https://openaccess.thecvf.com/content_CVPR_2019/papers/Girdhar_Video_Action_Transformer_Network_CVPR_2019_paper.html)
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
- [Image Transformer](http://proceedings.mlr.press/v80/parmar18a.html)
- [Jukebox: A Generative Model for Music](https://arxiv.org/abs/2005.00341)
- [Neural Style Transfer for Audio Spectrograms](https://arxiv.org/abs/1801.01589)
- [Neuralogram: A Deep Neural Network Based Representation for Audio Signals](https://arxiv.org/abs/1904.05073)
- [Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937)
- [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477)
- [vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations](https://arxiv.org/abs/1910.05453)
- [Conditional End-to-End Audio Transforms](https://arxiv.org/abs/1804.00047)
- [Audio-linguistic embeddings for spoken sentences](https://ieeexplore.ieee.org/document/8683615)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [FSD50K: An Open Dataset of Human-Labeled Sound Events](https://arxiv.org/abs/2010.00475)
- [SciPy 1.0: fundamental algorithms for scientific computing in Python](https://doi.org/10.1038/s41592-019-0686-2)
- [OpenNMT: Open-source toolkit for neural machine translation](https://doi.org/10.18653/v1/P17-4012)
- [Removing noise from music using local trigonometric bases and wavelet packets](https://www.aes.org/e-lib/browse.cfm?elib=11423)
- [Frequency estimation from waveforms using multi-layered neural networks](https://www.isca-speech.org/archive/interspeech_2016/pdfs/0351.pdf)
- [ImageNet: A large-scale hierarchical image database](https://ieeexplore.ieee.org/document/5206848)
- [Language through a prism: A spectral approach for multiscale language representations](https://proceedings.neurips.cc/paper/2020/hash/5c8a8e6b7714f72d35e7002e60029d4f-Abstract.html)
- [TensorFlow: A system for large-scale machine learning](https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi)
- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)
- [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/abs/2101.03961)
- [Generating Long Sequences with Sparse Transformers](https://arxiv.org/abs/1904.10509)
